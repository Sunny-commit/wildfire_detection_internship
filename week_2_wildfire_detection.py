# -*- coding: utf-8 -*-
"""Week-2-Wildfire-detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KTWDw7zIDZpg2rka4c05SxQIOh563p5E
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("elmadafri/the-wildfire-dataset")

print("Path to dataset files:", path)

"""# we have downloaded the dataset using kagglehub so it is saved in kaggle/input/ folder for privacy .so as to make it visible in content folder we are coping the folder in kaggle/input to content folder throug shutil .

"""

import shutil
import os

# Define source and destination paths
source_path = '/kaggle/input/the-wildfire-dataset'
destination_path = '/content/the-wildfire-dataset'

# Ensure the destination directory exists
os.makedirs(destination_path, exist_ok=True)

# Copy the dataset from source to destination
shutil.copytree(source_path, destination_path, dirs_exist_ok=True)

# Verify the copy operation
print(f"Contents of {destination_path}:")
print(os.listdir(destination_path))

"""Check is the folders are in content folder or nto"""

# List contents of the /content directory
os.listdir('/content')

# Importing necessary libraries
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input

# Load and explore the dataset
train_dir = '/content/the-wildfire-dataset/the_wildfire_dataset_2n_version/train'
val_dir = '/content/the-wildfire-dataset/the_wildfire_dataset_2n_version/val'
test_dir = '/content/the-wildfire-dataset/the_wildfire_dataset_2n_version/test'

# List all the classes
classes = os.listdir(train_dir)
num_classes = len(classes)

# Display the class names
print(f'Number of Classes: {num_classes}')
print(f'Classes: {classes}')

# Let's visualize the images in the dataset of no fire
plt.figure(figsize=(12, 10))
for i in range(5):
  class_path = os.path.join(train_dir, classes[0])
  img_name = os.listdir(class_path)[i]
  img_path = os.path.join(class_path, img_name)
  img = plt.imread(img_path)

  plt.subplot(1, 5, i+1)
  plt.imshow(img)
  plt.title(f'{classes[0]} \n shape: {img.shape}')
  plt.axis('off')
plt.show()

# Let's visualize the images in the dataset of fire
plt.figure(figsize=(12, 10))
for i in range(5):
  class_path = os.path.join(train_dir, classes[1])
  img_name = os.listdir(class_path)[i]
  img_path = os.path.join(class_path, img_name)
  img = plt.imread(img_path)

  plt.subplot(1, 5, i+1)
  plt.imshow(img)
  plt.title(f'{classes[1]} \n shape: {img.shape}')
  plt.axis('off')
plt.show()

"""Preprocessing

"""

# Preprocessing
# Image dimensions and batch size
img_width, img_height = 150, 150
batch_size = 32 # there will be 32 images in a batch!

# Data generators
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (img_width, img_height),
    batch_size = batch_size,
    class_mode = 'binary',
    shuffle = True
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size = (img_width, img_height),
    batch_size = batch_size,
    class_mode = 'binary',
    shuffle = True
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size = (img_width, img_height),
    batch_size = batch_size,
    class_mode = 'binary',
    shuffle = True
)

"""Mapping the indices"""

# map the indices
class_mapping = train_generator.class_indices
# print(class_mapping)
# Extract the class names
class_names = list(class_mapping.keys())
print("Class Names:", class_names)

"""CNN Model Training"""

# Let's build the CNN Model
model = Sequential([
    Input(shape=(img_width, img_height, 3)),
    Conv2D(32, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
]
)

